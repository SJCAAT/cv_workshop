{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/SJCAAT/cv_workshop/blob/main/workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2148799d",
   "metadata": {},
   "source": [
    "# **Computer Vision Workshop I&D 2025**\n",
    "Welcome to the workshop brought to you by members of the Computer Vision Capability group!\n",
    "\n",
    "In this hands-on session, we'll explore how computers can \"see\" the world using machine learning techniques. You'll get an introduction to Computer Vision, learn how object detection works and use a powerful, real-time model called **YOLOv8 (You Only Look Once version 8)** to detect objects in images and video.\n",
    "\n",
    "In this workshop we will be focussing on two main things:\n",
    "\n",
    "**1) Image classification**\n",
    "\n",
    "Here we implement a pre-trained model to classify images. You will have to import the necessary libraries and ensure the code refers to the correct images to get the model to work.\n",
    "\n",
    "**2) Live detection**\n",
    "\n",
    "After completing the image classification task, we will take it a step further by fine-tuning our model and using this for real-time object detection using our webcams.\n",
    "\n",
    "\n",
    "By the end of this workshop you'll be able to:\n",
    "- Understand basic concepts in computer vision.\n",
    "- Perform object detection with YOLOv8 using the [Ultralytics] library.\n",
    "- Run inference on static images and live webcam feeds.\n",
    "- Explore how to fine-tune YOLOv8 on your own dataset.\n",
    "\n",
    "Whether you're a beginner or have some experience with machine learning, this workshop is designed to be approachable and practical. \n",
    "\n",
    "Lets get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d07417b",
   "metadata": {},
   "source": [
    "# 1) Image Classification\n",
    "First we start with importing all the necessary libraries. Many of these are simply to present images and use the webcam in a notebook format, however the main library we are interested in is Ultralytics. Without this we do not have access to a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7631ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fbcec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image as pil_img\n",
    "from IPython.display import Image, display, Javascript, update_display\n",
    "from google.colab.output import eval_js\n",
    "from google.colab import files # for uploading images to test on\n",
    "from base64 import b64decode\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef84cc26",
   "metadata": {},
   "source": [
    "Now that we have imported all the necessary modules from various libraries we can start with loading a test image. The cell below allows you to upload any image you have stored on your local system. Download any image from the internet and use the code below to upload it.\n",
    "Alternatively, you may choose one of our sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your own image\n",
    "uploaded = files.upload()\n",
    "image_path = list(uploaded.keys())[0]\n",
    "print(f\"Uploaded image: {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f2a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display your image\n",
    "img = pil_img.open(image_path)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2afca13",
   "metadata": {},
   "source": [
    "If all went well you should see your test image above. With our test image ready we can use a pre-trained YOLO model to classify objects within that image.\n",
    "\n",
    "We start with choosing the model type. In this session we will be using a pre-trained YOLOv8 model from the ultralytics library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebee8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model predictions\n",
    "results = model(image_path) #can add conf if we want\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cec7d5",
   "metadata": {},
   "source": [
    "Hooray! If we got this far it means you've successfully implemented a YOLO model to classify a static image.\n",
    "If there is spare time, feel free to test with some more images that you can find on the web! Remember to change the image_path accordingly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d89755",
   "metadata": {},
   "source": [
    "# 2) Live Detection\n",
    "\n",
    "Now that we've seen the very basics of computer vision, lets take it a step further.\n",
    "\n",
    "In this scenario we are going to attempt to improve the model we just used on our initial images, and prepare it for live detection!\n",
    "\n",
    "In order to fine-tune the model we must have a dataset of images that we can train on. Fortunately for us, plenty of these exist and we can simply use the built-in Coco128 dataset (coco128.yaml). Due to our time constraints we limit the number of epochs (a complete pass through the entire training dataset) to three.\n",
    "\n",
    "Using the same model as before, use the '.train' command on the coco128.yaml dataset for 3 epochs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3669cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the coco128 dataset\n",
    "model.train(data='', epochs=)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800d3ff9",
   "metadata": {},
   "source": [
    "The beauty of YOLO is that we dont have to search for the best model ourselves. Instead, it automatically stores the best weights it found during training giving us easy access.\n",
    "\n",
    "\n",
    "Using the cell below, we create a model using the weights from training.\n",
    "\n",
    "You can inspect the results of training in the 'runs/detect/train/results.csv'. If you notice that you have a high loss and a low mAP50 this is an indication that training dit not go well and the model may not have actually improved. \n",
    "\n",
    "If this is the case and there is enough time, retrain the model and select the weights from the second training run and adjust the path in the cell below accordingly (runs/detect/train2/weights/best.pt). \n",
    "If there is not enough time to retrain, you may simply use the original pre-trained model we used in part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50715fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best weights found in training\n",
    "fine_tuned_model = YOLO('runs/detect/train/weights/best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06211ae",
   "metadata": {},
   "source": [
    "Now that we (hopefully) have our model fine-tuned, we can use it for live object detection using our webcams!\n",
    "\n",
    "The cells below may look a bit daunting, however we do not expect you to fully understand what is going on below. This is mainly to make sure the webcam works in the notebook version. You may inspect the code if you want but we have filled in everything so that it should work by simply executing the cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_photo(display_id: str, quality: float = 0.8) -> bytes:\n",
    "    # js snippet to capture frame from webcam\n",
    "    js = Javascript('''\n",
    "        async function takePhoto(quality) {\n",
    "            const div = document.createElement('div')\n",
    "            const video = document.createElement('video')\n",
    "            const stream = await navigator.mediaDevices.getUserMedia({video:true});\n",
    "\n",
    "            div.appendChild(video);\n",
    "            video.srcObject = stream;\n",
    "            await video.play();\n",
    "                    \n",
    "            const canvas = document.createElement('canvas');\n",
    "            canvas.width = video.videoWidth;\n",
    "            canvas.height = video.videoHeight;\n",
    "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "            stream.getVideoTracks()[0].stop();\n",
    "            div.remove();\n",
    "            return canvas.toDataURL('image/jpeg', quality);\n",
    "        }\n",
    "    ''')\n",
    "\n",
    "    # evaluate js and retrieve returned binary image\n",
    "    display(js, display_id=display_id)\n",
    "    data = eval_js('takePhoto({})'.format(quality))\n",
    "    binary = b64decode(data.split(',')[1])\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a864e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_image(model: YOLO, binary_img: bytes) -> np.array:\n",
    "    # Run inference on a binary image\n",
    "    img = np.array(pil_img.open(BytesIO(binary_img)))\n",
    "    results = model(img, verbose=False)\n",
    "    return results[0].plot(pil=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8939900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the same display\n",
    "display_id = 'sample_display'\n",
    "# load a pretrained yolov8 model\n",
    "model = YOLO('yolov8n') ## Change to 'fine_tuned_model' or keep this as is if fine-tuned was not great.\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # read a frame from the webcam\n",
    "        binary_img = take_photo(display_id='sample_display_2')\n",
    "        # run inference on the frame\n",
    "        result = infer_image(model, binary_img=binary_img)\n",
    "\n",
    "        # show the frame with the inference results\n",
    "        display(result, display_id=display_id)\n",
    "    except Exception as err:\n",
    "        # show error if user does not have a webcam or did not grant page permission\n",
    "        print(str(err))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
